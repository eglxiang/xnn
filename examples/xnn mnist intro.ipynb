{
 "metadata": {
  "name": "",
  "signature": "sha256:72245469f83f608b82be9a4541192ebf5071f7cfd912dee9628095d8d6f73590"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data loading"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading data into RAM in expected format and visualizing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mnist import *\n",
      "from pprint import pprint\n",
      "\n",
      "dataset = load_dataset()\n",
      "print dataset.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['X_test', 'X_train', 'y_train', 'X_valid', 'y_valid', 'y_test']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dataset['X_test'].dtype, dataset['y_test'].dtype\n",
      "print dataset['X_test'].shape, dataset['y_test'].shape\n",
      "print dataset['y_test'][0]\n",
      "imshow(dataset['X_test'][0].reshape(28,28), cmap=cm.gray, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "float32 float32\n",
        "(10000, 1, 28, 28) (10000, 10)\n",
        "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<matplotlib.image.AxesImage at 0x11eba7790>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQZeKsTAS4UYeKkQAy8VYuClQv4P/DqD7trN76gAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x11e4e4c90>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Breaking data into batches in callable form"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define generators\n",
      "# make a generator to yield a batch of data for training/validating\n",
      "class iterate_minibatches():\n",
      "    def __init__(self, dataset, batchsize, partition='train'):\n",
      "        self.dataset = dataset\n",
      "        self.batchsize = batchsize\n",
      "        self.partition = partition\n",
      "\n",
      "    def __call__(self):\n",
      "        inputs = self.dataset['X_'+self.partition]\n",
      "        targets = self.dataset['y_'+self.partition]\n",
      "        for start_idx in range(0, len(inputs) - self.batchsize + 1, self.batchsize):\n",
      "            excerpt = slice(start_idx, start_idx + self.batchsize)\n",
      "            batchdata = dict(\n",
      "                X=inputs[excerpt],\n",
      "                y=targets[excerpt]\n",
      "            )\n",
      "            yield batchdata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a train batch iterator and get a batch from it\n",
      "trainbatchit = iterate_minibatches(dataset, BATCHSIZE, 'train')\n",
      "it = trainbatchit()\n",
      "batch = it.next()\n",
      "print batch.keys()\n",
      "print batch['X'].shape, batch['X'].dtype\n",
      "\n",
      "# Note: 'X' and 'y' are the inputs and labels that will be bound to model layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['y', 'X']\n",
        "(500, 1, 28, 28) float32\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model building"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define an XNN model that is a container around layer graphs\n",
      "m = Model(\"MLP\")\n",
      "\n",
      "pprint(m.to_dict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'eval_outputs': OrderedDict(),\n",
        " 'inputs': OrderedDict(),\n",
        " 'layers': [],\n",
        " 'name': 'MLP',\n",
        " 'outputs': OrderedDict()}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This creates an MLP of two hidden layers of 800 units each, followed by\n",
      "# a softmax output layer of 10 units. It applies 20% dropout to the input\n",
      "# data and 50% dropout to the hidden layers.\n",
      "\n",
      "# Input layer, specifying the expected input shape of the network\n",
      "# (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
      "# linking it to the given Theano variable `input_var`, if any:\n",
      "\n",
      "l_in = m.add_layer(InputLayer((None, 1, 28, 28)))\n",
      "\n",
      "# Apply 20% dropout to the input data:\n",
      "l_in_drop = m.make_dropout_layer(l_in, p=0.2)\n",
      "\n",
      "# Add a stack of fully-connected layers of 800 units each with dropout\n",
      "l_stacktop = m.make_dense_drop_stack(l_in_drop, [800, 800], drop_p_list=[.5, .5])\n",
      "\n",
      "# Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
      "l_out = m.add_layer(DenseLayer(l_stacktop, num_units=10, nonlinearity=softmax), \"l_out\")\n",
      "\n",
      "pprint(m.to_dict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'eval_outputs': OrderedDict(),\n",
        " 'inputs': OrderedDict(),\n",
        " 'layers': [{'layer_type': 'InputLayer',\n",
        "             'name': 'InputLayer_0',\n",
        "             'output_shape': (None, 1, 28, 28),\n",
        "             'shape': (None, 1, 28, 28)},\n",
        "            {'incoming': 'InputLayer_0',\n",
        "             'input_shape': (None, 1, 28, 28),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_0',\n",
        "             'output_shape': (None, 1, 28, 28),\n",
        "             'p': 0.2,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_0',\n",
        "             'input_shape': (None, 1, 28, 28),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'DenseLayer_0',\n",
        "             'nonlinearity': 'rectify',\n",
        "             'num_units': 800,\n",
        "             'output_shape': (None, 800)},\n",
        "            {'incoming': 'DenseLayer_0',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_1',\n",
        "             'output_shape': (None, 800),\n",
        "             'p': 0.5,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_1',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'DenseLayer_1',\n",
        "             'nonlinearity': 'rectify',\n",
        "             'num_units': 800,\n",
        "             'output_shape': (None, 800)},\n",
        "            {'incoming': 'DenseLayer_1',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_2',\n",
        "             'output_shape': (None, 800),\n",
        "             'p': 0.5,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_2',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'l_out',\n",
        "             'nonlinearity': 'softmax',\n",
        "             'num_units': 10,\n",
        "             'output_shape': (None, 10)}],\n",
        " 'name': 'MLP',\n",
        " 'outputs': OrderedDict()}\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.bind_input(l_in, 'X')\n",
      "m.bind_output(l_out, categorical_crossentropy, 'y')\n",
      "\n",
      "pprint(m.to_dict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'eval_outputs': OrderedDict(),\n",
        " 'inputs': OrderedDict([('X', ['InputLayer_0'])]),\n",
        " 'layers': [{'layer_type': 'InputLayer',\n",
        "             'name': 'InputLayer_0',\n",
        "             'output_shape': (None, 1, 28, 28),\n",
        "             'shape': (None, 1, 28, 28)},\n",
        "            {'incoming': 'InputLayer_0',\n",
        "             'input_shape': (None, 1, 28, 28),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_0',\n",
        "             'output_shape': (None, 1, 28, 28),\n",
        "             'p': 0.2,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_0',\n",
        "             'input_shape': (None, 1, 28, 28),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'DenseLayer_0',\n",
        "             'nonlinearity': 'rectify',\n",
        "             'num_units': 800,\n",
        "             'output_shape': (None, 800)},\n",
        "            {'incoming': 'DenseLayer_0',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_1',\n",
        "             'output_shape': (None, 800),\n",
        "             'p': 0.5,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_1',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'DenseLayer_1',\n",
        "             'nonlinearity': 'rectify',\n",
        "             'num_units': 800,\n",
        "             'output_shape': (None, 800)},\n",
        "            {'incoming': 'DenseLayer_1',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DropoutLayer',\n",
        "             'name': 'DropoutLayer_2',\n",
        "             'output_shape': (None, 800),\n",
        "             'p': 0.5,\n",
        "             'rescale': True},\n",
        "            {'incoming': 'DropoutLayer_2',\n",
        "             'input_shape': (None, 800),\n",
        "             'layer_type': 'DenseLayer',\n",
        "             'name': 'l_out',\n",
        "             'nonlinearity': 'softmax',\n",
        "             'num_units': 10,\n",
        "             'output_shape': (None, 10)}],\n",
        " 'name': 'MLP',\n",
        " 'outputs': OrderedDict([('l_out', {'aggregation_type': 'mean', 'scale': 1.0, 'output_layer': 'l_out', 'weight_key': None, 'target': 'y', 'target_type': 'label', 'loss_function': 'categorical_crossentropy'})])}\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show the model graph\n",
      "modelgraphimg = xnn.utils.draw_to_file(m, '/tmp/modelgraph.png')\n",
      "modelgraphimg.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predict outputs before training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outs = m.predict(batch)\n",
      "print outs.keys()\n",
      "print outs['l_out'].shape\n",
      "print outs['l_out'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['DenseLayer_1', 'DenseLayer_0', 'InputLayer_0', 'DropoutLayer_2', 'DropoutLayer_1', 'DropoutLayer_0', 'l_out']\n",
        "(500, 10)\n",
        "[ 0.10237721  0.09038012  0.10468526  0.10239351  0.11265443  0.14392509\n",
        "  0.09767901  0.07645627  0.08882736  0.08062175]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Saving and loading model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m.save_model('/tmp/model.pkl')\n",
      "m2 = Model(\"loaded model\")\n",
      "m2.load_model('/tmp/model.pkl')\n",
      "outs2 = m2.predict(batch)\n",
      "print outs['l_out'][0] == outs2['l_out'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ True  True  True  True  True  True  True  True  True  True]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trainer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first set up global parameters for nesterov momentum\n",
      "global_update_settings = ParamUpdateSettings(\n",
      "    update=nesterov_momentum, learning_rate=0.25, momentum=0.9)\n",
      "\n",
      "# instantiate a trainer\n",
      "trainer = Trainer(m, global_update_settings)\n",
      "pprint(trainer.to_dict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'global_update_settings': {'settings': {'learning_rate': 0.25,\n",
        "                                         'momentum': 0.9},\n",
        "                            'update': 'nesterov_momentum'},\n",
        " 'layer_updates': {},\n",
        " 'model': 'MLP',\n",
        " 'regularizations': {}}\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Run some training steps on a batch and modify updates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set_printoptions(precision=3, suppress=True)\n",
      "print batch['y'][0]\n",
      "for i in range(5):\n",
      "    trainer.train_step(batch)\n",
      "    outs = m.predict(batch)\n",
      "    print outs['l_out'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
        "[ 0.144  0.125  0.103  0.097  0.08   0.044  0.107  0.113  0.07   0.118]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.145  0.082  0.081  0.159  0.062  0.068  0.115  0.103  0.091  0.094]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.117  0.094  0.077  0.217  0.034  0.12   0.081  0.077  0.105  0.079]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.055  0.029  0.037  0.37   0.016  0.177  0.059  0.067  0.116  0.075]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.048  0.02   0.06   0.352  0.002  0.266  0.033  0.021  0.169  0.029]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# decrease learning rate and continue training\n",
      "trainer.bind_global_update(ParamUpdateSettings(learning_rate=0.1))\n",
      "for i in range(10):\n",
      "    trainer.train_step(batch)\n",
      "    outs = m.predict(batch)\n",
      "    print outs['l_out'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.02   0.006  0.014  0.45   0.     0.344  0.014  0.009  0.132  0.011]\n",
        "[ 0.005  0.001  0.007  0.585  0.     0.312  0.005  0.004  0.077  0.004]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.004  0.     0.004  0.478  0.     0.434  0.002  0.001  0.075  0.001]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.003  0.     0.005  0.623  0.     0.323  0.001  0.001  0.045  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.001  0.356  0.     0.592  0.     0.     0.05   0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.002  0.798  0.     0.184  0.     0.     0.015  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.001  0.515  0.     0.455  0.     0.     0.028  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.     0.     0.     0.343  0.     0.643  0.     0.     0.014  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.001  0.342  0.     0.637  0.     0.     0.02   0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.003  0.379  0.     0.612  0.     0.     0.006  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add l2-regularization with weight .001 to weights to all layers\n",
      "trainer.bind_regularization(xnn.regularization.l2, .001)\n",
      "\n",
      "for i in range(5):\n",
      "    trainer.train_step(batch)\n",
      "    outs = m.predict(batch)\n",
      "    print outs['l_out'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.001  0.     0.001  0.408  0.     0.58   0.     0.     0.011  0.   ]\n",
        "[ 0.002  0.     0.001  0.247  0.     0.737  0.     0.     0.012  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.001  0.115  0.     0.877  0.     0.     0.006  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.001  0.     0.001  0.149  0.     0.83   0.     0.     0.018  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 0.002  0.     0.002  0.426  0.     0.565  0.     0.     0.005  0.   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Training loop"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's start the batch iteration from scratch and re-initialize the model\n",
      "trainbatchit = iterate_minibatches(dataset, BATCHSIZE, 'train')\n",
      "validbatchit = iterate_minibatches(dataset, BATCHSIZE, 'valid')\n",
      "\n",
      "# use a convenience function defined in mnist.py to build the same mlp as above \n",
      "m = build_mlp()\n",
      "trainer.set_model(m)\n",
      "\n",
      "# define some metrics to keep track of performance\n",
      "metrics = [\n",
      "    ('l_out', Metric(computeCategoricalCrossentropy, \"y\", aggregation_type=\"mean\"), 'min'),\n",
      "    ('l_out', Metric(computeOneHotAccuracy, \"y\", aggregation_type=\"none\"), 'max')\n",
      "]\n",
      "\n",
      "# create a training loop\n",
      "loop = Loop(trainer, trainbatchit, validbatchit, metrics, plotmetricmean=False)\n",
      "\n",
      "# iterate through 3 epochs of training on all data\n",
      "loop(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==========\n",
        "Epoch 0 / 2 -- 6.33 seconds\n",
        "Expected Finish: Wed, 11:58:13 AM\n",
        "----------\n",
        "Training total cost                                               :   2.0112 (best 2.0112 at epoch 0)\n",
        "----------\n",
        "Categorical Crossentropy                      l_out               :   0.2824 (best 0.2824 at epoch 0)\n",
        "Percent Correct                               l_out               :   0.9180 (best 0.9180 at epoch 0)\n",
        "=========="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1 / 2 -- 5.60 seconds\n",
        "Expected Finish: Wed, 11:58:12 AM\n",
        "----------\n",
        "Training total cost                                               :   1.2860 (best 1.2860 at epoch 1)\n",
        "----------\n",
        "Categorical Crossentropy                      l_out               :   0.2095 (best 0.2095 at epoch 1)\n",
        "Percent Correct                               l_out               :   0.9420 (best 0.9420 at epoch 1)\n",
        "=========="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2 / 2 -- 5.66 seconds\n",
        "Expected Finish: Wed, 11:58:11 AM\n",
        "----------\n",
        "Training total cost                                               :   0.9461 (best 0.9461 at epoch 2)\n",
        "----------\n",
        "Categorical Crossentropy                      l_out               :   0.1798 (best 0.1798 at epoch 2)\n",
        "Percent Correct                               l_out               :   0.9440 (best 0.9440 at epoch 2)\n",
        "Finished 3 epochs at 11:58:11 AM\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Experiment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from xnn.experiments import *\n",
      "# make an experiment condition class to store default variable values\n",
      "class _Condition(ExperimentCondition):\n",
      "    def __init__(self):\n",
      "        self.numhid = 100\n",
      "        self.hiddropout = .5\n",
      "        self.animal = 'vegetable'\n",
      "\n",
      "# add an experiment with a numhid factor testing several levels\n",
      "expt = Experiment(\"numhid experiment\", _Condition())\n",
      "expt.add_factor(\"numhid\", [100, 400, 800])\n",
      "expt.add_factor(\"hiddropout\", [0., .1, .25, .5])\n",
      "\n",
      "pprint(expt.to_dict())\n",
      "\n",
      "print '\\nnum conditions:', expt.get_num_conditions()\n",
      "print 'conditions:'\n",
      "pprint(expt.get_all_conditions_changes())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'default_condition': {'animal': 'vegetable',\n",
        "                       'hiddropout': 0.5,\n",
        "                       'numhid': 100},\n",
        " 'factors': {'hiddropout': [0.0, 0.1, 0.25, 0.5], 'numhid': [100, 400, 800]}}\n",
        "\n",
        "num conditions: 12\n",
        "conditions:\n",
        "{0: {'hiddropout': 0.0, 'numhid': 100},\n",
        " 1: {'hiddropout': 0.1, 'numhid': 100},\n",
        " 2: {'hiddropout': 0.25, 'numhid': 100},\n",
        " 3: {'hiddropout': 0.5, 'numhid': 100},\n",
        " 4: {'hiddropout': 0.0, 'numhid': 400},\n",
        " 5: {'hiddropout': 0.1, 'numhid': 400},\n",
        " 6: {'hiddropout': 0.25, 'numhid': 400},\n",
        " 7: {'hiddropout': 0.5, 'numhid': 400},\n",
        " 8: {'hiddropout': 0.0, 'numhid': 800},\n",
        " 9: {'hiddropout': 0.1, 'numhid': 800},\n",
        " 10: {'hiddropout': 0.25, 'numhid': 800},\n",
        " 11: {'hiddropout': 0.5, 'numhid': 800}}\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iterate over all conditions\n",
      "for cond in expt.get_conditions_iterator():\n",
      "    pprint(cond.to_dict())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'animal': 'vegetable', 'hiddropout': 0.0, 'numhid': 100}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.1, 'numhid': 100}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.25, 'numhid': 100}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.5, 'numhid': 100}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.0, 'numhid': 400}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.1, 'numhid': 400}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.25, 'numhid': 400}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.5, 'numhid': 400}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.0, 'numhid': 800}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.1, 'numhid': 800}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.25, 'numhid': 800}\n",
        "{'animal': 'vegetable', 'hiddropout': 0.5, 'numhid': 800}\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}