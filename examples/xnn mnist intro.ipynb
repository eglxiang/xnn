{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['show', 'figure', 'Figure', 'transpose', 'tanh', 'helper', 'reshape', 'pad', 'identity', 'shape', 'save', 'flatten']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into RAM in expected format and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test', 'X_train', 'y_train', 'X_valid', 'y_valid', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "from mnist import *\n",
    "from pprint import pprint\n",
    "random.seed(12345)\n",
    "\n",
    "dataset = load_dataset()\n",
    "print dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 float32\n",
      "(10000, 1, 28, 28) (10000, 10)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b45d090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQZeKsTAS4UYeKkQAy8VYuClQv4P/DqD7trN76gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae97490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print dataset['X_test'].dtype, dataset['y_test'].dtype\n",
    "print dataset['X_test'].shape, dataset['y_test'].shape\n",
    "print dataset['y_test'][0]\n",
    "imshow(dataset['X_test'][0].reshape(28,28), cmap=cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking data into batches in callable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define generators\n",
    "# make a generator to yield a batch of data for training/validating\n",
    "class iterate_minibatches():\n",
    "    def __init__(self, dataset, batchsize, partition='train'):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.partition = partition\n",
    "\n",
    "    def __call__(self):\n",
    "        inputs = self.dataset['X_'+self.partition]\n",
    "        targets = self.dataset['y_'+self.partition]\n",
    "        for start_idx in range(0, len(inputs) - self.batchsize + 1, self.batchsize):\n",
    "            excerpt = slice(start_idx, start_idx + self.batchsize)\n",
    "            batchdata = dict(\n",
    "                X=inputs[excerpt],\n",
    "                y=targets[excerpt]\n",
    "            )\n",
    "            yield batchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'X']\n",
      "(500, 1, 28, 28) float32\n"
     ]
    }
   ],
   "source": [
    "# make a train batch iterator and get a batch from it\n",
    "trainbatchit = iterate_minibatches(dataset, BATCHSIZE, 'train')\n",
    "it = trainbatchit()\n",
    "batch = it.next()\n",
    "print batch.keys()\n",
    "print batch['X'].shape, batch['X'].dtype\n",
    "\n",
    "# Note: 'X' and 'y' are the inputs and labels that will be bound to model layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_outputs': OrderedDict(),\n",
      " 'inputs': OrderedDict(),\n",
      " 'layers': [],\n",
      " 'name': 'MLP',\n",
      " 'outputs': OrderedDict()}\n"
     ]
    }
   ],
   "source": [
    "# Define an XNN model that is a container around layer graphs\n",
    "m = Model(\"MLP\")\n",
    "\n",
    "pprint(m.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_outputs': OrderedDict(),\n",
      " 'inputs': OrderedDict(),\n",
      " 'layers': [{'layer_type': 'InputLayer',\n",
      "             'name': 'InputLayer_0',\n",
      "             'output_shape': (None, 1, 28, 28),\n",
      "             'shape': (None, 1, 28, 28)},\n",
      "            {'incoming': 'InputLayer_0',\n",
      "             'input_shape': (None, 1, 28, 28),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_0',\n",
      "             'output_shape': (None, 1, 28, 28),\n",
      "             'p': 0.2,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_0',\n",
      "             'input_shape': (None, 1, 28, 28),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'DenseLayer_0',\n",
      "             'nonlinearity': 'rectify',\n",
      "             'num_units': 800,\n",
      "             'output_shape': (None, 800)},\n",
      "            {'incoming': 'DenseLayer_0',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_1',\n",
      "             'output_shape': (None, 800),\n",
      "             'p': 0.5,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_1',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'DenseLayer_1',\n",
      "             'nonlinearity': 'rectify',\n",
      "             'num_units': 800,\n",
      "             'output_shape': (None, 800)},\n",
      "            {'incoming': 'DenseLayer_1',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_2',\n",
      "             'output_shape': (None, 800),\n",
      "             'p': 0.5,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_2',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'l_out',\n",
      "             'nonlinearity': 'softmax',\n",
      "             'num_units': 10,\n",
      "             'output_shape': (None, 10)}],\n",
      " 'name': 'MLP',\n",
      " 'outputs': OrderedDict()}\n"
     ]
    }
   ],
   "source": [
    "# This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "# a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "# data and 50% dropout to the hidden layers.\n",
    "\n",
    "# Input layer, specifying the expected input shape of the network\n",
    "# (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "# linking it to the given Theano variable `input_var`, if any:\n",
    "\n",
    "l_in = m.add_layer(InputLayer((None, 1, 28, 28)))\n",
    "\n",
    "# Apply 20% dropout to the input data:\n",
    "l_in_drop = m.make_dropout_layer(l_in, p=0.2)\n",
    "\n",
    "# Add a stack of fully-connected layers of 800 units each with dropout\n",
    "l_stacktop = m.make_dense_drop_stack(l_in_drop, [800, 800], drop_p_list=[.5, .5])\n",
    "\n",
    "# Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "l_out = m.add_layer(DenseLayer(l_stacktop, num_units=10, nonlinearity=softmax), \"l_out\")\n",
    "\n",
    "pprint(m.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_outputs': OrderedDict(),\n",
      " 'inputs': OrderedDict([('X', ['InputLayer_0'])]),\n",
      " 'layers': [{'layer_type': 'InputLayer',\n",
      "             'name': 'InputLayer_0',\n",
      "             'output_shape': (None, 1, 28, 28),\n",
      "             'shape': (None, 1, 28, 28)},\n",
      "            {'incoming': 'InputLayer_0',\n",
      "             'input_shape': (None, 1, 28, 28),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_0',\n",
      "             'output_shape': (None, 1, 28, 28),\n",
      "             'p': 0.2,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_0',\n",
      "             'input_shape': (None, 1, 28, 28),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'DenseLayer_0',\n",
      "             'nonlinearity': 'rectify',\n",
      "             'num_units': 800,\n",
      "             'output_shape': (None, 800)},\n",
      "            {'incoming': 'DenseLayer_0',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_1',\n",
      "             'output_shape': (None, 800),\n",
      "             'p': 0.5,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_1',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'DenseLayer_1',\n",
      "             'nonlinearity': 'rectify',\n",
      "             'num_units': 800,\n",
      "             'output_shape': (None, 800)},\n",
      "            {'incoming': 'DenseLayer_1',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DropoutLayer',\n",
      "             'name': 'DropoutLayer_2',\n",
      "             'output_shape': (None, 800),\n",
      "             'p': 0.5,\n",
      "             'rescale': True},\n",
      "            {'incoming': 'DropoutLayer_2',\n",
      "             'input_shape': (None, 800),\n",
      "             'layer_type': 'DenseLayer',\n",
      "             'name': 'l_out',\n",
      "             'nonlinearity': 'softmax',\n",
      "             'num_units': 10,\n",
      "             'output_shape': (None, 10)}],\n",
      " 'name': 'MLP',\n",
      " 'outputs': OrderedDict([('l_out', {'aggregation_type': 'mean', 'scale': 1.0, 'output_layer': 'l_out', 'weight_key': None, 'target': 'y', 'target_type': 'label', 'loss_function': 'categorical_crossentropy'})])}\n"
     ]
    }
   ],
   "source": [
    "m.bind_input(l_in, 'X')\n",
    "m.bind_output(l_out, categorical_crossentropy, 'y')\n",
    "\n",
    "pprint(m.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the model graph\n",
    "modelgraphimg = xnn.utils.draw_to_file(m, '/tmp/modelgraph.png')\n",
    "modelgraphimg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict outputs before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DenseLayer_1', 'DenseLayer_0', 'InputLayer_0', 'DropoutLayer_2', 'DropoutLayer_1', 'DropoutLayer_0', 'l_out']\n",
      "(500, 10)\n",
      "[ 0.05717566  0.11806224  0.11426906  0.1212244   0.06255973  0.13076602\n",
      "  0.088493    0.10443017  0.10315738  0.09986234]\n"
     ]
    }
   ],
   "source": [
    "outs = m.predict(batch)\n",
    "print outs.keys()\n",
    "print outs['l_out'].shape\n",
    "print outs['l_out'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "m.save_model('/tmp/model.pkl')\n",
    "m2 = Model(\"loaded model\")\n",
    "m2.load_model('/tmp/model.pkl')\n",
    "outs2 = m2.predict(batch)\n",
    "print outs['l_out'][0] == outs2['l_out'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_update_settings': {'settings': {'learning_rate': 0.25,\n",
      "                                         'momentum': 0.9},\n",
      "                            'update': 'nesterov_momentum'},\n",
      " 'layer_updates': {},\n",
      " 'model': 'MLP',\n",
      " 'regularizations': {}}\n"
     ]
    }
   ],
   "source": [
    "# first set up global parameters for nesterov momentum\n",
    "global_update_settings = ParamUpdateSettings(\n",
    "    update=nesterov_momentum, learning_rate=0.25, momentum=0.9)\n",
    "\n",
    "# instantiate a trainer\n",
    "trainer = Trainer(m, global_update_settings)\n",
    "pprint(trainer.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some training steps on a batch and modify updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.216  0.078  0.026  0.106  0.099  0.08   0.074  0.057  0.1    0.163]\n",
      "[ 0.025  0.097  0.056  0.284  0.049  0.118  0.076  0.103  0.104  0.087]\n",
      "[ 0.08   0.062  0.047  0.242  0.044  0.127  0.065  0.084  0.123  0.127]\n",
      "[ 0.042  0.026  0.015  0.598  0.012  0.097  0.022  0.052  0.086  0.05 ]\n",
      "[ 0.016  0.016  0.014  0.458  0.007  0.217  0.02   0.029  0.154  0.068]\n"
     ]
    }
   ],
   "source": [
    "set_printoptions(precision=3, suppress=True)\n",
    "print batch['y'][0]\n",
    "for i in range(5):\n",
    "    trainer.train_step(batch)\n",
    "    outs = m.predict(batch)\n",
    "    print outs['l_out'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.006  0.003  0.004  0.647  0.001  0.224  0.004  0.013  0.076  0.021]\n",
      "[ 0.003  0.001  0.001  0.73   0.     0.208  0.001  0.003  0.046  0.006]\n",
      "[ 0.002  0.     0.001  0.727  0.     0.237  0.     0.001  0.029  0.003]\n",
      "[ 0.002  0.     0.001  0.782  0.     0.173  0.     0.001  0.04   0.001]\n",
      "[ 0.001  0.     0.     0.794  0.     0.194  0.     0.     0.011  0.   ]\n",
      "[ 0.     0.     0.     0.899  0.     0.095  0.     0.     0.006  0.   ]\n",
      "[ 0.     0.     0.     0.832  0.     0.16   0.     0.     0.008  0.   ]\n",
      "[ 0.     0.     0.     0.833  0.     0.143  0.     0.     0.024  0.   ]\n",
      "[ 0.     0.     0.     0.688  0.     0.301  0.     0.     0.011  0.   ]\n",
      "[ 0.     0.     0.     0.482  0.     0.511  0.     0.     0.007  0.   ]\n"
     ]
    }
   ],
   "source": [
    "# decrease learning rate and continue training\n",
    "trainer.bind_global_update(ParamUpdateSettings(learning_rate=0.1))\n",
    "for i in range(10):\n",
    "    trainer.train_step(batch)\n",
    "    outs = m.predict(batch)\n",
    "    print outs['l_out'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     0.     0.     0.807  0.     0.185  0.     0.     0.008  0.   ]\n",
      "[ 0.001  0.     0.     0.597  0.     0.392  0.     0.     0.01   0.   ]\n",
      "[ 0.     0.     0.     0.279  0.     0.713  0.     0.     0.007  0.   ]\n",
      "[ 0.001  0.     0.     0.27   0.     0.722  0.     0.     0.006  0.   ]\n",
      "[ 0.001  0.     0.001  0.331  0.     0.655  0.     0.     0.011  0.   ]\n"
     ]
    }
   ],
   "source": [
    "# add l2-regularization with weight .001 to weights to all layers\n",
    "trainer.bind_regularization(xnn.regularization.l2, .001)\n",
    "\n",
    "for i in range(5):\n",
    "    trainer.train_step(batch)\n",
    "    outs = m.predict(batch)\n",
    "    print outs['l_out'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 0 / 2 -- 6.48 seconds\n",
      "Expected Finish: Wed, 01:36:06 PM\n",
      "----------\n",
      "Training total cost                                               :   2.0117 (best 2.0117 at epoch 0)\n",
      "----------\n",
      "Categorical Crossentropy                      l_out               :   0.2868 (best 0.2868 at epoch 0)\n",
      "Percent Correct                               l_out               :   0.9200 (best 0.9200 at epoch 0)\n",
      "==========\n",
      "Epoch 1 / 2 -- 5.63 seconds\n",
      "Expected Finish: Wed, 01:36:04 PM\n",
      "----------\n",
      "Training total cost                                               :   1.2867 (best 1.2867 at epoch 1)\n",
      "----------\n",
      "Categorical Crossentropy                      l_out               :   0.2127 (best 0.2127 at epoch 1)\n",
      "Percent Correct                               l_out               :   0.9420 (best 0.9420 at epoch 1)\n",
      "==========\n",
      "Epoch 2 / 2 -- 5.57 seconds\n",
      "Expected Finish: Wed, 01:36:04 PM\n",
      "----------\n",
      "Training total cost                                               :   0.9445 (best 0.9445 at epoch 2)\n",
      "----------\n",
      "Categorical Crossentropy                      l_out               :   0.1712 (best 0.1712 at epoch 2)\n",
      "Percent Correct                               l_out               :   0.9520 (best 0.9520 at epoch 2)\n",
      "Finished 3 epochs at 01:36:04 PM\n"
     ]
    }
   ],
   "source": [
    "# let's start the batch iteration from scratch and re-initialize the model\n",
    "trainbatchit = iterate_minibatches(dataset, BATCHSIZE, 'train')\n",
    "validbatchit = iterate_minibatches(dataset, BATCHSIZE, 'valid')\n",
    "\n",
    "# use a convenience function defined in mnist.py to build the same mlp as above \n",
    "m = build_mlp()\n",
    "trainer.set_model(m)\n",
    "\n",
    "# define some metrics to keep track of performance\n",
    "metrics = [\n",
    "    ('l_out', Metric(computeCategoricalCrossentropy, \"y\", aggregation_type=\"mean\"), 'min'),\n",
    "    ('l_out', Metric(computeOneHotAccuracy, \"y\", aggregation_type=\"none\"), 'max')\n",
    "]\n",
    "\n",
    "# create a training loop\n",
    "loop = Loop(trainer, trainbatchit, validbatchit, metrics, plotmetricmean=False)\n",
    "\n",
    "# iterate through 3 epochs of training on all data\n",
    "loop(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default_condition': {'hiddropout': 0.5, 'numhid': 100},\n",
      " 'factors': {'hiddropout': [0.0, 0.1, 0.25, 0.5], 'numhid': [100, 400, 800]}}\n",
      "\n",
      "num conditions: 12\n",
      "conditions:\n",
      "{0: {'hiddropout': 0.0, 'numhid': 100},\n",
      " 1: {'hiddropout': 0.1, 'numhid': 100},\n",
      " 2: {'hiddropout': 0.25, 'numhid': 100},\n",
      " 3: {'hiddropout': 0.5, 'numhid': 100},\n",
      " 4: {'hiddropout': 0.0, 'numhid': 400},\n",
      " 5: {'hiddropout': 0.1, 'numhid': 400},\n",
      " 6: {'hiddropout': 0.25, 'numhid': 400},\n",
      " 7: {'hiddropout': 0.5, 'numhid': 400},\n",
      " 8: {'hiddropout': 0.0, 'numhid': 800},\n",
      " 9: {'hiddropout': 0.1, 'numhid': 800},\n",
      " 10: {'hiddropout': 0.25, 'numhid': 800},\n",
      " 11: {'hiddropout': 0.5, 'numhid': 800}}\n"
     ]
    }
   ],
   "source": [
    "from xnn.experiments import *\n",
    "# make an experiment condition class to store default variable values\n",
    "class _Condition(ExperimentCondition):\n",
    "    def __init__(self):\n",
    "        self.numhid = 100\n",
    "        self.hiddropout = .5\n",
    "\n",
    "# add an experiment with a numhid factor testing several levels\n",
    "expt = Experiment(\"numhid experiment\", _Condition())\n",
    "expt.add_factor(\"numhid\", [100, 400, 800])\n",
    "expt.add_factor(\"hiddropout\", [0., .1, .25, .5])\n",
    "\n",
    "pprint(expt.to_dict())\n",
    "\n",
    "print '\\nnum conditions:', expt.get_num_conditions()\n",
    "print 'conditions:'\n",
    "pprint(expt.get_all_conditions_changes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hiddropout': 0.0, 'numhid': 100}\n",
      "{'hiddropout': 0.1, 'numhid': 100}\n",
      "{'hiddropout': 0.25, 'numhid': 100}\n",
      "{'hiddropout': 0.5, 'numhid': 100}\n",
      "{'hiddropout': 0.0, 'numhid': 400}\n",
      "{'hiddropout': 0.1, 'numhid': 400}\n",
      "{'hiddropout': 0.25, 'numhid': 400}\n",
      "{'hiddropout': 0.5, 'numhid': 400}\n",
      "{'hiddropout': 0.0, 'numhid': 800}\n",
      "{'hiddropout': 0.1, 'numhid': 800}\n",
      "{'hiddropout': 0.25, 'numhid': 800}\n",
      "{'hiddropout': 0.5, 'numhid': 800}\n"
     ]
    }
   ],
   "source": [
    "# iterate over all conditions\n",
    "for cond in expt.get_conditions_iterator():\n",
    "    pprint(cond.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hiddropout': ('hiddropout', 0.5), 'numhid': 100}\n",
      "{'hiddropout': ('hiddropout', 0.5), 'numhid': 400}\n",
      "{'hiddropout': ('hiddropout', 0.5), 'numhid': 800}\n"
     ]
    }
   ],
   "source": [
    "# iterate over numhid, holding hiddropout fixed at 0.5\n",
    "for cond in expt.get_conditions_slice_iterator(['numhid'],{'hiddropout':0.5}):\n",
    "    pprint(cond.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
